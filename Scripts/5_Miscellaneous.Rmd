---
title: "5 Miscellaneous"
author: "Luiz Felipe & Francisco"
date: "`r Sys.Date()`"
output: html_document
---

# 0. Packages

```{r}
library(ggplot2)
library(dplyr)
library(sf)
library(tmap)
library(lubridate)
library(daymetr)
library(janitor)
library(tidyverse)
library(leaflet)
library(leaflet.extras)
library(raster)
library(rmapshaper)
library(rnassqs)
library(gganimate)
library(gifski)
library(transformr)
```

# 1. Coordinates

```{r}
# Show a map of the USA
usa <- st_as_sf(maps::map("usa", plot = FALSE, fill = TRUE))

ggplot(usa) + 
  geom_sf(fill = "grey95") + 
  theme_minimal()

# Filter just Kansas
states <- st_as_sf(maps::map("state", plot = FALSE, fill = TRUE))
kansas <- states %>% filter(ID == "kansas")

ggplot(kansas) + 
  geom_sf(fill = "grey95") + 
  theme_minimal()

# Load Kansas counties
ks_counties <- st_as_sf(maps::map("county", "kansas", plot = FALSE, fill = TRUE))

df_points <- readRDS("Data/coordinates_KScounty.RDS")

# Plot the counties and the random points
ggplot() +
  geom_sf(data = ks_counties, fill = "#512888", alpha = 1, color = "black") +
  geom_sf(data = df_points, shape = 21, fill = "gold", size = 2) +
  theme_minimal()
```

# 2. Download weather data

```{r}
# Extract coordinates from the random points
coords <- data.frame(st_coordinates(df_points)) %>% 
  rowid_to_column("ID") %>% 
  rename(lon = X, lat = Y)

# Initialize an empty data frame to store the weather data
df_daymetr <- data.frame()

# Loop through each point and download weather data
for (i in 1:nrow(coords)) {
  # Get the longitude and latitude for the current point
  longitude <- coords[i, "lon"]
  latitude <- coords[i, "lat"]
  
  # Download weather data using the daymetr package
  df_data <- download_daymet(
    site = paste0(i),  
    lat = latitude,
    lon = longitude,
    start = 2023,
    end = 2023,
    internal = TRUE
  )
  
  # Extract the site metadata
  site_info <- tibble(
    site = df_data$site,
    tile = df_data$tile,
    latitude = df_data$latitude,
    longitude = df_data$longitude,
    altitude = df_data$altitude
  )

  # Extract and tidy up the daily weather data
  df_tidy <- df_data$data %>%
    mutate(ID = site_info$site,
           tile = site_info$tile,
           latitude = site_info$latitude,
           longitude = site_info$longitude,
           altitude = site_info$altitude) %>%
    dplyr::select(year, yday, dayl..s., prcp..mm.day., srad..W.m.2., swe..kg.m.2., 
           tmax..deg.c., tmin..deg.c., vp..Pa., ID, tile, latitude, longitude, altitude)
  
  # Add the data to the main data frame
  df_daymetr <- bind_rows(df_daymetr, df_tidy)
}

# Wrangling with the lubridate library
df_weather <- df_daymetr %>%
  mutate(date = as.Date(yday - 1, origin = paste0(year, "-01-01"))) %>%
  dplyr::select(ID, latitude, longitude, altitude, date, dayl..s., prcp..mm.day., 
         srad..W.m.2., swe..kg.m.2., tmax..deg.c., tmin..deg.c., vp..Pa.) %>% 
  clean_names()

# Basic summary of weather data
summary(df_weather)
```

## i) Summarise weather

```{r}
# Calculate mean temperature and precipitation
df_summary <- df_weather %>%
  group_by(id, latitude, longitude) %>%
  summarise(total_precip = sum(prcp_mm_day, na.rm = TRUE)) %>%
  ungroup()
```

## ii) Leaflet plot

```{r}
# Create the leaflet map with total precipitation points
leaflet(df_summary) %>%
  addProviderTiles(providers$Esri.NatGeoWorldMap) %>%  
  addCircleMarkers(
    ~longitude, ~latitude,
    fillColor = ~colorNumeric(palette = c("red", "green"), domain = df_summary$total_precip)(total_precip),  
    fillOpacity = 0.7,
    color = "black",
    radius = 6, 
    stroke = TRUE,
    weight = 1,
    popup = ~paste0("Location: ", id, "<br>Total Precipitation: ", round(total_precip, 2), " mm")
  ) %>%
  addLegend(
    pal = colorNumeric(palette = c("red", "green"), domain = df_summary$total_precip),
    values = df_summary$total_precip,
    title = "Total precipitation (mm)",
    position = "topright"
  ) %>%
  setView(lng = mean(df_summary$longitude), lat = mean(df_summary$latitude), zoom = 7)
```


# 3. Crop information

```{r}
# https://quickstats.nass.usda.gov/api
# Next: Obtain API key

NASSQS_TOKEN <- "YOUR-KEY" 

nassqs_auth(key = NASSQS_TOKEN)

params <- list(
  commodity_desc = "CORN",
  year__GE = 1995,  
  agg_level_desc = "COUNTY",
  state_alpha = "KS",
  statisticcat_desc = "YIELD")

df_yield <- nassqs(params)
unique(df_yield$county_name)

# We need to match the same county name
df_countyname <- ks_counties %>%
  mutate(county_name = gsub("kansas,", "", ID)) %>%
  mutate(county_name = toupper(county_name))

head(df_countyname)

# All upper-case
df_yield <- df_yield %>%
  mutate(county_name = toupper(county_name))

# Now merge the datasets
df_yield_sf <- df_countyname %>%
  left_join(df_yield, by = "county_name")

# Inspect the merged data
head(df_yield_sf)
```

```{r fig.height=8, fig.width=10}
ggplot(df_yield_sf) +
  geom_sf(aes(fill = as.numeric(Value)), color = "black", size = 0.2) +
  scale_fill_gradient(low = "wheat", high = "forestgreen", na.value = NA, name = "Corn yield (bu/acre)") +
  theme_bw() +
  labs(title = "County-level corn yield (KS, 2023)",
       subtitle = "Data Source: USDA NASS",
       caption = "Created by: Ciamitti Lab (September 30, 2024)")+
  facet_wrap(~year, ncol = 5)+
  theme(axis.text.x = element_text(angle = 90),
        legend.position = "bottom")
```

### i) County-level

```{r}
df_yield_gif <- df_yield_sf %>%
  mutate(year = as.numeric(year))

# Create the ggplot object with gganimate
gif_yield <- ggplot(df_yield_sf) +
  geom_sf(aes(fill = as.numeric(Value)), color = "black", size = 0.2) +
  scale_fill_gradient(low = "wheat", high = "forestgreen", na.value = "white", name = "Corn yield (bu/acre)") +
  theme_minimal() +
  labs(title = "Year: {current_frame}",
       fill = "Yield (bu/acre)") +
  theme(axis.text.x = element_text(angle = 90),
        legend.position = "bottom") +
  transition_manual(year)

animate(gif_yield, 
        nframes = length(unique(df_yield_sf$year)) * 10, 
        fps = 10, width = 800, height = 600, renderer = gifski_renderer("images/nass_corn_1995.gif"))
```

### ii) State-level

```{r message=FALSE, warning=FALSE}
# Set parameters to get data for CORN YIELD across the US for years 1995 and onwards
params_state <- list(
  commodity_desc = "CORN",
  year__GE = 1995,  
  agg_level_desc = "STATE", 
  statisticcat_desc = "YIELD")

# Fetch the data using the corrected parameters
df_yield_state <- nassqs(params_state) %>% 
  mutate(Value = as.numeric(Value),
         year = as.numeric(year)) %>% 
  group_by(state_name, year) %>%
  summarise(mean_yield = mean(Value, na.rm = TRUE)) %>%
  ungroup()

# Create the ggplot object with gganimate
gif_trends <- ggplot(df_yield_state, aes(x = year, y = mean_yield, group = state_name, color = state_name)) +
  geom_line(size = 1) +
  scale_color_viridis_d() +  # Use a colorblind-friendly palette
  theme_bw() +
  labs(x = "Year",
       y = "Average corn yield (bu/acre)",
       color = "State") +
  transition_reveal(along = year) +
  theme(legend.position = "none")

animate(gif_trends, nframes = 200, fps = 10, width = 800, height = 600, renderer = gifski_renderer("images/nass_states.gif"))
```

### iii) Country-level

```{r message=FALSE, warning=FALSE}
df_yield_us <- nassqs(params_state) %>% 
  mutate(Value = as.numeric(Value),
         year = as.numeric(year)) %>% 
  group_by(year) %>%
  summarise(mean_yield = mean(Value, na.rm = TRUE)) %>%
  ungroup()

# Create the ggplot object with gganimate
gif_us <- ggplot(df_yield_us, aes(x = year, y = mean_yield)) +
  geom_line(size = 1, color = "red") +
  scale_color_viridis_d(option = "C") +
  scale_x_continuous(n.breaks = 27) +
  theme_bw() +
  labs(x = "Year",
       y = "Average corn yield (bu/acre)") +
  transition_reveal(year)

animate(gif_us, nframes = 200, fps = 10, width = 800, height = 600, renderer = gifski_renderer("images/nass_usa.gif"))
```




































